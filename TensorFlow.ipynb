{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d30e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import torch\n",
    "import importlib\n",
    "import cv2 \n",
    "\n",
    "from shutil import copyfile\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from PIL import Image\n",
    "from string import Template\n",
    "from IPython.display import display\n",
    "\n",
    "TRAIN_PATH = 'C:\\\\Users\\\\yangd\\\\Documents\\\\Python_Scripts\\\\TensorFlow\\\\tensorflow-great-barrier-reef'\n",
    "\n",
    "import codecs, sys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deee6ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.10.0+cpu\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:35_Pacific_Daylight_Time_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0\n"
     ]
    }
   ],
   "source": [
    "# check Torch and CUDA version\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd4a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'YOLOX' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\yangd\\anaconda3\\lib\\site-packages (21.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.19.2)\n",
      "Requirement already satisfied: torch>=1.7 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.10.0)\n",
      "Requirement already satisfied: opencv_python in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (4.5.4.60)\n",
      "Requirement already satisfied: loguru in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.18.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (4.62.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (0.11.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (8.3.1)\n",
      "Requirement already satisfied: thop in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (0.0.31.post2005241907)\n",
      "Requirement already satisfied: ninja in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.2.3)\n",
      "Requirement already satisfied: tabulate in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (0.8.9)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (2.4.0)\n",
      "Requirement already satisfied: onnx==1.8.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 16)) (1.8.1)\n",
      "Requirement already satisfied: onnxruntime==1.8.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (1.8.0)\n",
      "Requirement already satisfied: onnx-simplifier==0.3.5 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 18)) (0.3.5)\n",
      "Requirement already satisfied: six in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (3.17.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (3.10.0.0)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from onnxruntime==1.8.0->-r requirements.txt (line 17)) (2.0)\n",
      "Requirement already satisfied: onnxoptimizer>=0.2.5 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from onnx-simplifier==0.3.5->-r requirements.txt (line 18)) (0.2.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from loguru->-r requirements.txt (line 5)) (1.0.4)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from loguru->-r requirements.txt (line 5)) (0.4.4)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from scikit-image->-r requirements.txt (line 6)) (1.6.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from scikit-image->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from scikit-image->-r requirements.txt (line 6)) (2.6.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from scikit-image->-r requirements.txt (line 6)) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from scikit-image->-r requirements.txt (line 6)) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (1.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (1.21.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (0.37.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (1.36.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 13)) (0.13.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\yangd\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (3.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 21.2.2 from C:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\pip (python 3.8)\n",
      "Obtaining file:///C:/Users/yangd/Documents/Python_Scripts/TensorFlow/YOLOX\n",
      "Installing collected packages: yolox\n",
      "  Attempting uninstall: yolox\n",
      "    Found existing installation: yolox 0.1.0\n",
      "    Uninstalling yolox-0.1.0:\n",
      "      Removing file or directory c:\\users\\yangd\\anaconda3\\lib\\site-packages\\yolox.egg-link\n",
      "      Removing pth entries from c:\\users\\yangd\\anaconda3\\lib\\site-packages\\easy-install.pth:\n",
      "      Removing entry: c:\\users\\yangd\\documents\\python_scripts\\tensorflow\\yolox\n",
      "      Successfully uninstalled yolox-0.1.0\n",
      "  Running setup.py develop for yolox\n",
      "Successfully installed yolox-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Running command python setup.py egg_info\n",
      "    No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0'\n",
      "    running egg_info\n",
      "    creating C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\n",
      "    writing C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\\PKG-INFO\n",
      "    writing dependency_links to C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\\dependency_links.txt\n",
      "    writing top-level names to C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\\top_level.txt\n",
      "    writing manifest file 'C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\\SOURCES.txt'\n",
      "    reading manifest file 'C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\\SOURCES.txt'\n",
      "    writing manifest file 'C:\\Users\\yangd\\AppData\\Local\\Temp\\pip-pip-egg-info-zin089p0\\yolox.egg-info\\SOURCES.txt'\n",
      "    Error in atexit._run_exitfuncs:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\", line 59, in closed\n",
      "        return stream.closed\n",
      "    ValueError: underlying buffer has been detached\n",
      "    Running command 'C:\\Users\\yangd\\Anaconda3\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\yangd\\\\Documents\\\\Python_Scripts\\\\TensorFlow\\\\YOLOX\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\yangd\\\\Documents\\\\Python_Scripts\\\\TensorFlow\\\\YOLOX\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
      "    No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0'\n",
      "    running develop\n",
      "    running egg_info\n",
      "    writing yolox.egg-info\\PKG-INFO\n",
      "    writing dependency_links to yolox.egg-info\\dependency_links.txt\n",
      "    writing top-level names to yolox.egg-info\\top_level.txt\n",
      "    reading manifest file 'yolox.egg-info\\SOURCES.txt'\n",
      "    writing manifest file 'yolox.egg-info\\SOURCES.txt'\n",
      "    running build_ext\n",
      "    building 'yolox._C' extension\n",
      "    Emitting ninja build file C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\build\\temp.win-amd64-3.8\\Release\\build.ninja...\n",
      "    Compiling objects...\n",
      "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "    C:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:316: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "      warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "    ninja: no work to do.\n",
      "    C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.30.30705\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\torch\\lib /LIBPATH:C:\\Users\\yangd\\Anaconda3\\libs /LIBPATH:C:\\Users\\yangd\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.30.30705\\ATLMFC\\lib\\x64\" \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.30.30705\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64\" c10.lib torch.lib torch_cpu.lib torch_python.lib /EXPORT:PyInit__C C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\build\\temp.win-amd64-3.8\\Release\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\layers\\csrc\\vision.obj C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\build\\temp.win-amd64-3.8\\Release\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\layers\\csrc\\cocoeval\\cocoeval.obj /OUT:build\\lib.win-amd64-3.8\\yolox\\_C.cp38-win_amd64.pyd /IMPLIB:C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\build\\temp.win-amd64-3.8\\Release\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\layers\\csrc\\_C.cp38-win_amd64.lib\n",
      "       Creating library C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\build\\temp.win-amd64-3.8\\Release\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\layers\\csrc\\_C.cp38-win_amd64.lib and object C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\build\\temp.win-amd64-3.8\\Release\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\layers\\csrc\\_C.cp38-win_amd64.exp\n",
      "    Generating code\n",
      "    Finished generating code\n",
      "    copying build\\lib.win-amd64-3.8\\yolox\\_C.cp38-win_amd64.pyd -> yolox\n",
      "    Creating c:\\users\\yangd\\anaconda3\\lib\\site-packages\\yolox.egg-link (link to .)\n",
      "    Adding yolox 0.1.0 to easy-install.pth file\n",
      "\n",
      "    Installed c:\\users\\yangd\\documents\\python_scripts\\tensorflow\\yolox\n",
      "    Error in atexit._run_exitfuncs:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\", line 59, in closed\n",
      "        return stream.closed\n",
      "    ValueError: underlying buffer has been detached\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Megvii-BaseDetection/YOLOX -q\n",
    "\n",
    "%cd YOLOX\n",
    "!pip install -U pip && pip install -r requirements.txt\n",
    "!pip install -v -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e461f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "def get_path(row):\n",
    "    row['image_path'] = f'{TRAIN_PATH}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82b1444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0-3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  sequence  video_frame  sequence_frame image_id annotations\n",
       "0         0     40258            0               0      0-0          []\n",
       "1         0     40258            1               1      0-1          []\n",
       "2         0     40258            2               2      0-2          []\n",
       "3         0     40258            3               3      0-3          []\n",
       "4         0     40258            4               4      0-4          []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\yangd\\\\Documents\\\\Python_Scripts\\\\TensorFlow\\\\tensorflow-great-barrier-reef\\\\train.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b613ae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50a75a2207246e49ac556c2cd0c3cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce8730882e44cf194692ee39bda5918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67938058baee47ca94d78a980b97c584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taken only annotated photos\n",
    "df[\"num_bbox\"] = df['annotations'].apply(lambda x: str.count(x, 'x'))\n",
    "df_train = df[df[\"num_bbox\"]>0]\n",
    "\n",
    "#Annotations \n",
    "df_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\n",
    "df_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n",
    "\n",
    "#Images resolution\n",
    "df_train[\"width\"] = 1280\n",
    "df_train[\"height\"] = 720\n",
    "\n",
    "#Path of images\n",
    "df_train = df_train.progress_apply(get_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0756ce10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>num_bbox</th>\n",
       "      <th>bboxes</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0-16</td>\n",
       "      <td>[{'x': 559, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[559, 213, 50, 32]]</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>[{'x': 558, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[558, 213, 50, 32]]</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0-18</td>\n",
       "      <td>[{'x': 557, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[557, 213, 50, 32]]</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0-19</td>\n",
       "      <td>[{'x': 556, 'y': 214, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[556, 214, 50, 32]]</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>[{'x': 555, 'y': 214, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[555, 214, 50, 32]]</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  sequence  video_frame  sequence_frame image_id  \\\n",
       "0         0     40258           16              16     0-16   \n",
       "1         0     40258           17              17     0-17   \n",
       "2         0     40258           18              18     0-18   \n",
       "3         0     40258           19              19     0-19   \n",
       "4         0     40258           20              20     0-20   \n",
       "\n",
       "                                         annotations  num_bbox  \\\n",
       "0  [{'x': 559, 'y': 213, 'width': 50, 'height': 32}]         1   \n",
       "1  [{'x': 558, 'y': 213, 'width': 50, 'height': 32}]         1   \n",
       "2  [{'x': 557, 'y': 213, 'width': 50, 'height': 32}]         1   \n",
       "3  [{'x': 556, 'y': 214, 'width': 50, 'height': 32}]         1   \n",
       "4  [{'x': 555, 'y': 214, 'width': 50, 'height': 32}]         1   \n",
       "\n",
       "                 bboxes  width  height  \\\n",
       "0  [[559, 213, 50, 32]]   1280     720   \n",
       "1  [[558, 213, 50, 32]]   1280     720   \n",
       "2  [[557, 213, 50, 32]]   1280     720   \n",
       "3  [[556, 214, 50, 32]]   1280     720   \n",
       "4  [[555, 214, 50, 32]]   1280     720   \n",
       "\n",
       "                                          image_path  fold  \n",
       "0  C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...     4  \n",
       "1  C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...     4  \n",
       "2  C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...     4  \n",
       "3  C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...     4  \n",
       "4  C:\\Users\\yangd\\Documents\\Python_Scripts\\Tensor...     4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = GroupKFold(n_splits = 5) \n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y = df_train.video_id.tolist(), groups=df_train.sequence)):\n",
    "    df_train.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "127e06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\dataset already exists.\n",
      "A subdirectory or file C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\dataset\\images already exists.\n",
      "A subdirectory or file C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\dataset\\images\\\\train2017 already exists.\n",
      "A subdirectory or file C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\dataset\\images\\\\val2017 already exists.\n",
      "A subdirectory or file C:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\dataset\\images\\\\annotations already exists.\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = 'C:\\\\Users\\\\yangd\\\\Documents\\\\Python_Scripts\\\\TensorFlow\\\\' \n",
    "DATASET_PATH = 'dataset\\\\images'\n",
    "\n",
    "!mkdir {HOME_DIR}dataset\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}\\\\train2017\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}\\\\val2017\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}\\\\annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2f2cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0f8f305a5f4310910eeb41c45301eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECTED_FOLD = 4\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    row = df_train.loc[i]\n",
    "    if row.fold != SELECTED_FOLD:\n",
    "        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/train2017/{row.image_id}.jpg')\n",
    "    else:\n",
    "        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/val2017/{row.image_id}.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f5f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 3974\n",
      "Number of validation files: 945\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/train2017/\"))}')\n",
    "print(f'Number of validation files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/val2017/\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6f2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_annot_json(json_annotation, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        output_json = json.dumps(json_annotation)\n",
    "        f.write(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c658780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotion_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c3f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset2coco(df, dest_path):\n",
    "    \n",
    "    global annotion_id\n",
    "    \n",
    "    annotations_json = {\n",
    "        \"info\": [],\n",
    "        \"licenses\": [],\n",
    "        \"categories\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    info = {\n",
    "        \"year\": \"2021\",\n",
    "        \"version\": \"1\",\n",
    "        \"description\": \"COTS dataset - COCO format\",\n",
    "        \"contributor\": \"\",\n",
    "        \"url\": \"https://kaggle.com\",\n",
    "        \"date_created\": \"2021-11-30T15:01:26+00:00\"\n",
    "    }\n",
    "    annotations_json[\"info\"].append(info)\n",
    "    \n",
    "    lic = {\n",
    "            \"id\": 1,\n",
    "            \"url\": \"\",\n",
    "            \"name\": \"Unknown\"\n",
    "        }\n",
    "    annotations_json[\"licenses\"].append(lic)\n",
    "\n",
    "    classes = {\"id\": 0, \"name\": \"starfish\", \"supercategory\": \"none\"}\n",
    "\n",
    "    annotations_json[\"categories\"].append(classes)\n",
    "\n",
    "    \n",
    "    for ann_row in df.itertuples():\n",
    "            \n",
    "        images = {\n",
    "            \"id\": ann_row[0],\n",
    "            \"license\": 1,\n",
    "            \"file_name\": ann_row.image_id + '.jpg',\n",
    "            \"height\": ann_row.height,\n",
    "            \"width\": ann_row.width,\n",
    "            \"date_captured\": \"2021-11-30T15:01:26+00:00\"\n",
    "        }\n",
    "        \n",
    "        annotations_json[\"images\"].append(images)\n",
    "        \n",
    "        bbox_list = ann_row.bboxes\n",
    "        \n",
    "        for bbox in bbox_list:\n",
    "            b_width = bbox[2]\n",
    "            b_height = bbox[3]\n",
    "            \n",
    "            # some boxes in COTS are outside the image height and width\n",
    "            if (bbox[0] + bbox[2] > 1280):\n",
    "                b_width = bbox[0] - 1280 \n",
    "            if (bbox[1] + bbox[3] > 720):\n",
    "                b_height = bbox[1] - 720 \n",
    "                \n",
    "            image_annotations = {\n",
    "                \"id\": annotion_id,\n",
    "                \"image_id\": ann_row[0],\n",
    "                \"category_id\": 0,\n",
    "                \"bbox\": [bbox[0], bbox[1], b_width, b_height],\n",
    "                \"area\": bbox[2] * bbox[3],\n",
    "                \"segmentation\": [],\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            \n",
    "            annotion_id += 1\n",
    "            annotations_json[\"annotations\"].append(image_annotations)\n",
    "        \n",
    "        \n",
    "    print(f\"Dataset COTS annotation to COCO json format completed! Files: {len(df)}\")\n",
    "    return annotations_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63cfdf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset COTS annotation to COCO json format completed! Files: 3974\n",
      "Dataset COTS annotation to COCO json format completed! Files: 945\n"
     ]
    }
   ],
   "source": [
    "# Convert COTS dataset to JSON COCO\n",
    "train_annot_json = dataset2coco(df_train[df_train.fold != SELECTED_FOLD], f\"{HOME_DIR}{DATASET_PATH}/train2017/\")\n",
    "val_annot_json = dataset2coco(df_train[df_train.fold == SELECTED_FOLD], f\"{HOME_DIR}{DATASET_PATH}/val2017/\")\n",
    "\n",
    "# Save converted annotations\n",
    "save_annot_json(train_annot_json, f\"{HOME_DIR}{DATASET_PATH}/annotations/train.json\")\n",
    "save_annot_json(val_annot_json, f\"{HOME_DIR}{DATASET_PATH}/annotations/valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7370407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model for your experiments NANO or YOLOX-S (you can adapt for other model type)\n",
    "\n",
    "NANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "873e7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_template = '''\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "# Copyright (c) Megvii, Inc. and its affiliates.\n",
    "\n",
    "import os\n",
    "\n",
    "from yolox.exp import Exp as MyExp\n",
    "\n",
    "\n",
    "class Exp(MyExp):\n",
    "    def __init__(self):\n",
    "        super(Exp, self).__init__()\n",
    "        self.depth = 0.33\n",
    "        self.width = 0.50\n",
    "        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n",
    "        \n",
    "        # Define yourself dataset path\n",
    "        self.data_dir = \"/kaggle/working/dataset/images\"\n",
    "        self.train_ann = \"train.json\"\n",
    "        self.val_ann = \"valid.json\"\n",
    "\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.max_epoch = $max_epoch\n",
    "        self.data_num_workers = 2\n",
    "        self.eval_interval = 1\n",
    "        \n",
    "        self.mosaic_prob = 1.0\n",
    "        self.mixup_prob = 1.0\n",
    "        self.hsv_prob = 1.0\n",
    "        self.flip_prob = 0.5\n",
    "        self.no_aug_epochs = 2\n",
    "        \n",
    "        self.input_size = (960, 960)\n",
    "        self.mosaic_scale = (0.5, 1.5)\n",
    "        self.random_size = (10, 20)\n",
    "        self.test_size = (960, 960)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a1e8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NANO:\n",
    "    config_file_template = '''\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "# Copyright (c) Megvii, Inc. and its affiliates.\n",
    "\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from yolox.exp import Exp as MyExp\n",
    "\n",
    "\n",
    "class Exp(MyExp):\n",
    "    def __init__(self):\n",
    "        super(Exp, self).__init__()\n",
    "        self.depth = 0.33\n",
    "        self.width = 0.25\n",
    "        self.input_size = (416, 416)\n",
    "        self.mosaic_scale = (0.5, 1.5)\n",
    "        self.random_size = (10, 20)\n",
    "        self.test_size = (416, 416)\n",
    "        self.exp_name = os.path.split(\n",
    "            os.path.realpath(__file__))[1].split(\".\")[0]\n",
    "        self.enable_mixup = False\n",
    "\n",
    "        # Define yourself dataset path\n",
    "        self.data_dir = \"/kaggle/working/dataset/images\"\n",
    "        self.train_ann = \"train.json\"\n",
    "        self.val_ann = \"valid.json\"\n",
    "\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.max_epoch = $max_epoch\n",
    "        self.data_num_workers = 2\n",
    "        self.eval_interval = 1\n",
    "\n",
    "    def get_model(self, sublinear=False):\n",
    "        def init_yolo(M):\n",
    "            for m in M.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eps = 1e-3\n",
    "                    m.momentum = 0.03\n",
    "\n",
    "        if \"model\" not in self.__dict__:\n",
    "            from yolox.models import YOLOX, YOLOPAFPN, YOLOXHead\n",
    "            in_channels = [256, 512, 1024]\n",
    "            # NANO model use depthwise = True, which is main difference.\n",
    "            backbone = YOLOPAFPN(self.depth,\n",
    "                                 self.width,\n",
    "                                 in_channels=in_channels,\n",
    "                                 depthwise=True)\n",
    "            head = YOLOXHead(self.num_classes,\n",
    "                             self.width,\n",
    "                             in_channels=in_channels,\n",
    "                             depthwise=True)\n",
    "            self.model = YOLOX(backbone, head)\n",
    "\n",
    "        self.model.apply(init_yolo)\n",
    "        self.model.head.initialize_biases(1e-2)\n",
    "        return self.model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60009a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH='cots_config.py'\n",
    "\n",
    "pipeline = Template(config_file_template).substitute(max_epoch = 20)\n",
    "\n",
    "with open(PIPELINE_CONFIG_PATH, 'w') as f:\n",
    "    f.write(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58570281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./yolox/data/datasets/voc_classes.py\n",
    "\n",
    "voc_cls = '''\n",
    "VOC_CLASSES = (\n",
    "  \"starfish\",\n",
    ")\n",
    "'''\n",
    "with open('.\\\\yolox\\\\data\\\\datasets\\\\voc_classes.py', 'w') as f:\n",
    "    f.write(voc_cls)\n",
    "\n",
    "# ./yolox/data/datasets/coco_classes.py\n",
    "\n",
    "coco_cls = '''\n",
    "COCO_CLASSES = (\n",
    "  \"starfish\",\n",
    ")\n",
    "'''\n",
    "with open('.\\\\yolox\\\\data\\\\datasets\\\\coco_classes.py', 'w') as f:\n",
    "    f.write(coco_cls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ba9dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if everything is ok    \n",
    "%more .\\\\yolox\\\\data\\\\datasets\\\\coco_classes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9399e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sh = 'wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth'\n",
    "MODEL_FILE = 'yolox_s.pth'\n",
    "\n",
    "if NANO:\n",
    "    sh = '''\n",
    "    wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_nano.pth\n",
    "    '''\n",
    "    MODEL_FILE = 'yolox_nano.pth'\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "  file.write(sh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddfd446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./tools/train.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7d83b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "facab8a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logging error in Loguru Handler #2 ---\n",
      "--- Logging error in Loguru Handler #2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32m2021-12-17 23:15:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1margs: Namespace(batch_size=32, cache=False, ckpt='yolox_s.pth', devices=1, dist_backend='nccl', dist_url=None, exp_file='cots_config.py', experiment_name='cots_config', fp16=True, machine_rank=0, name=None, num_machines=1, occupy=True, opts=['#', 'Remember', 'to', 'change', 'this', 'line', 'if', 'you', 'take', 'different', 'model', 'eg.', 'yolo_nano.pth,', 'yolox_s.pth', 'or', 'yolox_m.pth'], resume=False, start_epoch=None)\u001b[0m\n",
      "\u001b[32m2021-12-17 23:15:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mexp value:\n",
      "\\u2552\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2564\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2555\n",
      "\\u2502 keys             \\u2502 values                           \\u2502\n",
      "\\u255e\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u256a\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2561\n",
      "\\u2502 seed             \\u2502 None                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 output_dir       \\u2502 './YOLOX_outputs'                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 print_interval   \\u2502 10                               \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 eval_interval    \\u2502 1                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 num_classes      \\u2502 1                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 depth            \\u2502 0.33                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 width            \\u2502 0.5                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 act              \\u2502 'silu'                           \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 data_num_workers \\u2502 2                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 input_size       \\u2502 (960, 960)                       \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 multiscale_range \\u2502 5                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 data_dir         \\u2502 '/kaggle/working/dataset/images' \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 train_ann        \\u2502 'train.json'                     \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 val_ann          \\u2502 'valid.json'                     \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 mosaic_prob      \\u2502 1.0                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 mixup_prob       \\u2502 1.0                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 hsv_prob         \\u2502 1.0                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 flip_prob        \\u2502 0.5                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 degrees          \\u2502 10.0                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 translate        \\u2502 0.1                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 mosaic_scale     \\u2502 (0.5, 1.5)                       \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 mixup_scale      \\u2502 (0.5, 1.5)                       \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 shear            \\u2502 2.0                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 enable_mixup     \\u2502 True                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 warmup_epochs    \\u2502 5                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 max_epoch        \\u2502 20                               \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 warmup_lr        \\u2502 0                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 basic_lr_per_img \\u2502 0.00015625                       \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 scheduler        \\u2502 'yoloxwarmcos'                   \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 no_aug_epochs    \\u2502 2                                \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 min_lr_ratio     \\u2502 0.05                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 ema              \\u2502 True                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 weight_decay     \\u2502 0.0005                           \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 momentum         \\u2502 0.9                              \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 exp_name         \\u2502 'cots_config'                    \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 test_size        \\u2502 (960, 960)                       \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 test_conf        \\u2502 0.01                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 nmsthre          \\u2502 0.65                             \\u2502\n",
      "\\u251c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2524\n",
      "\\u2502 random_size      \\u2502 (10, 20)                         \\u2502\n",
      "\\u2558\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2567\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u255b\u001b[0m\n",
      "\u001b[32m2021-12-17 23:15:19\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m98\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function 'launch', process 'MainProcess' (40920), thread 'MainThread' (40404):\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\loguru\\\u001b[0m\u001b[32m\u001b[1m_handler.py\u001b[0m\", line \u001b[33m177\u001b[0m, in \u001b[35memit\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_sink\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mwrite\u001b[0m\u001b[1m(\u001b[0m\u001b[1mstr_record\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|    |     |     -> \u001b[0m\u001b[36m\u001b[1m\"2021-12-17 23:15:19.813 | INFO     | yolox.core.trainer:before_train:127 - exp value:\\n\\u2552\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2564\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550...\u001b[0m\n",
      "    \u001b[36m|    |     -> \u001b[0m\u001b[36m\u001b[1m<function FileSink.write at 0x000001B912F83700>\u001b[0m\n",
      "    \u001b[36m|    -> \u001b[0m\u001b[36m\u001b[1m<loguru._file_sink.FileSink object at 0x000001B91C222D30>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m(id=2, level=10, sink='./YOLOX_outputs\\cots_config\\train_log.txt')\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\loguru\\\u001b[0m\u001b[32m\u001b[1m_file_sink.py\u001b[0m\", line \u001b[33m176\u001b[0m, in \u001b[35mwrite\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_file\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mwrite\u001b[0m\u001b[1m(\u001b[0m\u001b[1mmessage\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|    |     |     -> \u001b[0m\u001b[36m\u001b[1m\"2021-12-17 23:15:19.813 | INFO     | yolox.core.trainer:before_train:127 - exp value:\\n\\u2552\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2564\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550...\u001b[0m\n",
      "    \u001b[36m|    |     -> \u001b[0m\u001b[36m\u001b[1m<method 'write' of '_io.TextIOWrapper' objects>\u001b[0m\n",
      "    \u001b[36m|    -> \u001b[0m\u001b[36m\u001b[1m<_io.TextIOWrapper name='C:\\\\Users\\\\yangd\\\\Documents\\\\Python_Scripts\\\\TensorFlow\\\\YOLOX\\\\YOLOX_outputs\\\\cots_config\\\\train_lo...\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<loguru._file_sink.FileSink object at 0x000001B91C222D30>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Anaconda3\\lib\\encodings\\\u001b[0m\u001b[32m\u001b[1mcp1252.py\u001b[0m\", line \u001b[33m19\u001b[0m, in \u001b[35mencode\u001b[0m\n",
      "    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mcodecs\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mcharmap_encode\u001b[0m\u001b[1m(\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1merrors\u001b[0m\u001b[1m,\u001b[0m\u001b[1mencoding_table\u001b[0m\u001b[1m)\u001b[0m\u001b[1m[\u001b[0m\u001b[34m\u001b[1m0\u001b[0m\u001b[1m]\u001b[0m\n",
      "    \u001b[36m       |      |              |     |    |      -> \u001b[0m\u001b[36m\u001b[1m<EncodingMap object at 0x000001B9105DF200>\u001b[0m\n",
      "    \u001b[36m       |      |              |     |    -> \u001b[0m\u001b[36m\u001b[1m'strict'\u001b[0m\n",
      "    \u001b[36m       |      |              |     -> \u001b[0m\u001b[36m\u001b[1m<encodings.cp1252.IncrementalEncoder object at 0x000001B91C222D60>\u001b[0m\n",
      "    \u001b[36m       |      |              -> \u001b[0m\u001b[36m\u001b[1m\"2021-12-17 23:15:19.813 | INFO     | yolox.core.trainer:before_train:127 - exp value:\\r\\n\\u2552\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2564\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550...\u001b[0m\n",
      "    \u001b[36m       |      -> \u001b[0m\u001b[36m\u001b[1m<built-in function charmap_encode>\u001b[0m\n",
      "    \u001b[36m       -> \u001b[0m\u001b[36m\u001b[1m<module 'codecs' from 'C:\\\\Users\\\\yangd\\\\Anaconda3\\\\lib\\\\codecs.py'>\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mUnicodeEncodeError\u001b[0m:\u001b[1m 'charmap' codec can't encode characters in position 87-141: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"\u001b[32m\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m125\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1mlaunch\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<function launch at 0x000001B919F23EE0>\u001b[0m\n",
      "\n",
      "> File \"\u001b[32mC:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\core\\\u001b[0m\u001b[32m\u001b[1mlaunch.py\u001b[0m\", line \u001b[33m98\u001b[0m, in \u001b[35mlaunch\u001b[0m\n",
      "    \u001b[1mmain_func\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|          -> \u001b[0m\u001b[36m\u001b[1m(\\u2552\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2564\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2555\u001b[0m\n",
      "    \u001b[36m|             \u001b[0m\u001b[36m\u001b[1m\\u2502 keys             \\u2502 values                           \\u2502\u001b[0m\n",
      "    \u001b[36m|             \u001b[0m\u001b[36m\u001b[1m\\u255e\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550...\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<function main at 0x000001B91C1F6EE0>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32m\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m110\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[1mtrainer\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|       -> \u001b[0m\u001b[36m\u001b[1m<function Trainer.train at 0x000001B91A6D81F0>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x000001B91C200760>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\core\\\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m70\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbefore_train\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|    -> \u001b[0m\u001b[36m\u001b[1m<function Trainer.before_train at 0x000001B91C19BD30>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x000001B91C200760>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\core\\\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m127\u001b[0m, in \u001b[35mbefore_train\u001b[0m\n",
      "    \u001b[1mlogger\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1minfo\u001b[0m\u001b[1m(\u001b[0m\u001b[36m\"exp value:\\n{}\"\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mformat\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mexp\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|      |                            |    -> \u001b[0m\u001b[36m\u001b[1m\\u2552\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2564\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2555\u001b[0m\n",
      "    \u001b[36m|      |                            |       \u001b[0m\u001b[36m\u001b[1m\\u2502 keys             \\u2502 values                           \\u2502\u001b[0m\n",
      "    \u001b[36m|      |                            |       \u001b[0m\u001b[36m\u001b[1m\\u255e\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550...\u001b[0m\n",
      "    \u001b[36m|      |                            -> \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x000001B91C200760>\u001b[0m\n",
      "    \u001b[36m|      -> \u001b[0m\u001b[36m\u001b[1m<function Logger.info at 0x000001B912FAB280>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<loguru.logger handlers=[(id=1, level=20, sink=<stderr>), (id=2, level=10, sink='./YOLOX_outputs\\cots_config\\train_log.txt')]>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\loguru\\\u001b[0m\u001b[32m\u001b[1m_handler.py\u001b[0m\", line \u001b[33m182\u001b[0m, in \u001b[35memit\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_error_interceptor\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mprint\u001b[0m\u001b[1m(\u001b[0m\u001b[1mrecord\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|    |                  |     -> \u001b[0m\u001b[36m\u001b[1m{'elapsed': datetime.timedelta(seconds=2, microseconds=342635), 'exception': None, 'extra': {}, 'file': (name='trainer.py', p...\u001b[0m\n",
      "    \u001b[36m|    |                  -> \u001b[0m\u001b[36m\u001b[1m<function ErrorInterceptor.print at 0x000001B912F22280>\u001b[0m\n",
      "    \u001b[36m|    -> \u001b[0m\u001b[36m\u001b[1m<loguru._error_interceptor.ErrorInterceptor object at 0x000001B91C222C70>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m(id=2, level=10, sink='./YOLOX_outputs\\cots_config\\train_log.txt')\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Anaconda3\\lib\\site-packages\\loguru\\\u001b[0m\u001b[32m\u001b[1m_error_interceptor.py\u001b[0m\", line \u001b[33m28\u001b[0m, in \u001b[35mprint\u001b[0m\n",
      "    \u001b[1msys\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mstderr\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mwrite\u001b[0m\u001b[1m(\u001b[0m\u001b[36m\"Record was: %s\\n\"\u001b[0m \u001b[35m\u001b[1m%\u001b[0m \u001b[1mrecord_repr\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|   |      |                          -> \u001b[0m\u001b[36m\u001b[1m'{\\'elapsed\\': datetime.timedelta(seconds=2, microseconds=342635), \\'exception\\': None, \\'extra\\': {}, \\'file\\': (name=\\'trai...\u001b[0m\n",
      "    \u001b[36m|   |      -> \u001b[0m\u001b[36m\u001b[1m<function StreamToLoguru.write at 0x000001B919CA33A0>\u001b[0m\n",
      "    \u001b[36m|   -> \u001b[0m\u001b[36m\u001b[1m<yolox.utils.logger.StreamToLoguru object at 0x000001B91C222E50>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<module 'sys' (built-in)>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Documents\\Python_Scripts\\TensorFlow\\YOLOX\\yolox\\utils\\\u001b[0m\u001b[32m\u001b[1mlogger.py\u001b[0m\", line \u001b[33m51\u001b[0m, in \u001b[35mwrite\u001b[0m\n",
      "    \u001b[1msys\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m__stdout__\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mwrite\u001b[0m\u001b[1m(\u001b[0m\u001b[1mbuf\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m|   |          |     -> \u001b[0m\u001b[36m\u001b[1m'Record was: {\\'elapsed\\': datetime.timedelta(seconds=2, microseconds=342635), \\'exception\\': None, \\'extra\\': {}, \\'file\\': ...\u001b[0m\n",
      "    \u001b[36m|   |          -> \u001b[0m\u001b[36m\u001b[1m<method 'write' of '_io.TextIOWrapper' objects>\u001b[0m\n",
      "    \u001b[36m|   -> \u001b[0m\u001b[36m\u001b[1m<_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp1252'>\u001b[0m\n",
      "    \u001b[36m-> \u001b[0m\u001b[36m\u001b[1m<module 'sys' (built-in)>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mC:\\Users\\yangd\\Anaconda3\\lib\\encodings\\\u001b[0m\u001b[32m\u001b[1mcp1252.py\u001b[0m\", line \u001b[33m19\u001b[0m, in \u001b[35mencode\u001b[0m\n",
      "    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mcodecs\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mcharmap_encode\u001b[0m\u001b[1m(\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1merrors\u001b[0m\u001b[1m,\u001b[0m\u001b[1mencoding_table\u001b[0m\u001b[1m)\u001b[0m\u001b[1m[\u001b[0m\u001b[34m\u001b[1m0\u001b[0m\u001b[1m]\u001b[0m\n",
      "    \u001b[36m       |      |              |     |    |      -> \u001b[0m\u001b[36m\u001b[1m<EncodingMap object at 0x000001B9105DF200>\u001b[0m\n",
      "    \u001b[36m       |      |              |     |    -> \u001b[0m\u001b[36m\u001b[1m'surrogateescape'\u001b[0m\n",
      "    \u001b[36m       |      |              |     -> \u001b[0m\u001b[36m\u001b[1m<encodings.cp1252.IncrementalEncoder object at 0x000001B910908130>\u001b[0m\n",
      "    \u001b[36m       |      |              -> \u001b[0m\u001b[36m\u001b[1m'Record was: {\\'elapsed\\': datetime.timedelta(seconds=2, microseconds=342635), \\'exception\\': None, \\'extra\\': {}, \\'file\\': ...\u001b[0m\n",
      "    \u001b[36m       |      -> \u001b[0m\u001b[36m\u001b[1m<built-in function charmap_encode>\u001b[0m\n",
      "    \u001b[36m       -> \u001b[0m\u001b[36m\u001b[1m<module 'codecs' from 'C:\\\\Users\\\\yangd\\\\Anaconda3\\\\lib\\\\codecs.py'>\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mUnicodeEncodeError\u001b[0m:\u001b[1m 'charmap' codec can't encode characters in position 297-298: character maps to <undefined>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "    -f cots_config.py \\\n",
    "    -d 1 \\\n",
    "    -b 32 \\\n",
    "    --fp16 \\\n",
    "    -o \\\n",
    "    -c {MODEL_FILE}   # Remember to change this line if you take different model eg. yolo_nano.pth, yolox_s.pth or yolox_m.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c3981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
